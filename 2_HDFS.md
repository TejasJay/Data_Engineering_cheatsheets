# **ðŸ”¥ Step 1: Introduction to Hadoop & HDFS**

### **ðŸ“Œ What is HDFS?**

HDFS (**Hadoop Distributed File System**) is a **fault-tolerant, distributed file system** designed to store **large-scale data** across multiple machines.

âœ… **Why use HDFS?**

-   Handles **huge datasets** (terabytes to petabytes).
-   **Scalable** â€“ Adds more nodes as storage grows.
-   **Fault-tolerant** â€“ Replicates data across machines.
* * *

## **ðŸ”¥ Step 2: HDFS Components**

HDFS has a **Master-Slave Architecture**:

| **Component** | **Function** |
| --- | --- |
| **NameNode (Master)** | Manages metadata (file locations, permissions, replication info). |
| **DataNodes (Slaves)** | Store actual data blocks. |
| **Secondary NameNode** | Helps in metadata checkpointing (not a failover node). |

* * *

## **ðŸ”¥ Step 3: Install & Start HDFS**

### **âœ… 1. Format the NameNode (Prepares HDFS for First-Time Use)**

bash

CopyEdit

`hdfs namenode -format`

ðŸ“Œ **What does this do?**

-   Initializes the **metadata storage** of the NameNode.
-   Deletes old metadata and creates a **fresh file system**.
* * *

### **âœ… 2. Start HDFS Services**

bash

CopyEdit

`start-dfs.sh`

ðŸ“Œ **What does this do?**

-   Starts **NameNode (Master)** and **DataNodes (Workers)** in the cluster.
-   Allows files to be stored and retrieved in HDFS.

ðŸ”¹ **Verify services are running:**

bash

CopyEdit

`jps`

ðŸ“Œ **What does this show?**

-   Lists running Hadoop processes (`NameNode`, `DataNode`, `SecondaryNameNode`).
* * *

### **âœ… 3. Check HDFS Cluster Status**

bash

CopyEdit

`hdfs dfsadmin -report`

ðŸ“Œ **What does this do?**

-   Displays **live DataNodes, total storage, free space, and replication factor**.
* * *

# **ðŸ”¥ Step 4: Basic HDFS Commands (Hands-On)**

ðŸ“Œ **Now letâ€™s create directories, upload files, move, and delete files in HDFS.**

* * *

### **âœ… 1. Create Directories in HDFS**

bash

CopyEdit

`hdfs dfs -mkdir /user/your_username`

ðŸ“Œ **What does this do?**

-   Creates a new directory `/user/your_username` inside HDFS.
-   Similar to `mkdir` in Linux, but for HDFS.

bash

CopyEdit

`hdfs dfs -mkdir /user/your_username/input hdfs dfs -mkdir /user/your_username/output`

ðŸ“Œ **Why create multiple directories?**

-   `/input` â†’ Stores raw files.
-   `/output` â†’ Stores processed data.

ðŸ”¹ **Verify directories were created:**

bash

CopyEdit

`hdfs dfs -ls /user/your_username`

ðŸ“Œ **What does this do?**

-   Lists all files and directories inside `/user/your_username`.
* * *

### **âœ… 2. Upload Files to HDFS**

bash

CopyEdit

`echo "Hadoop is a distributed file system" > localfile.txt hdfs dfs -put localfile.txt /user/your_username/input/`

ðŸ“Œ **What does this do?**

-   Creates a sample file `localfile.txt` in local storage.
-   `put` uploads the file to HDFS under `/user/your_username/input/`.

ðŸ”¹ **Verify file was uploaded:**

bash

CopyEdit

`hdfs dfs -ls /user/your_username/input/`

ðŸ“Œ **What does this do?**

-   Lists all files in `/user/your_username/input/` inside HDFS.
* * *

### **âœ… 3. Read Files from HDFS**

bash

CopyEdit

`hdfs dfs -cat /user/your_username/input/localfile.txt`

ðŸ“Œ **What does this do?**

-   Reads and displays the content of `localfile.txt` stored inside HDFS.
-   Similar to `cat` in Linux.
* * *

### **âœ… 4. Download Files from HDFS**

bash

CopyEdit

`hdfs dfs -get /user/your_username/input/localfile.txt .`

ðŸ“Œ **What does this do?**

-   Retrieves `localfile.txt` from HDFS and saves it in the **current directory (`.`)**.

bash

CopyEdit

`hdfs dfs -copyToLocal /user/your_username/input/localfile.txt .`

ðŸ“Œ **Whatâ€™s the difference?**

-   Both `get` and `copyToLocal` copy files from HDFS to the local file system.
-   `get` provides **progress status**, while `copyToLocal` doesnâ€™t.
* * *

### **âœ… 5. Rename & Move Files in HDFS**

bash

CopyEdit

`hdfs dfs -mv /user/your_username/input/localfile.txt /user/your_username/input/data.txt`

ðŸ“Œ **What does this do?**

-   Renames `localfile.txt` to `data.txt`.

bash

CopyEdit

`hdfs dfs -mv /user/your_username/input/data.txt /user/your_username/output/`

ðŸ“Œ **What does this do?**

-   Moves `data.txt` from `/input/` to `/output/`.

ðŸ”¹ **Check if the file was moved:**

bash

CopyEdit

`hdfs dfs -ls /user/your_username/output/`

ðŸ“Œ **What does this do?**

-   Lists the contents of `/output/` to verify the move.
* * *

### **âœ… 6. Delete Files & Directories in HDFS**

bash

CopyEdit

`hdfs dfs -rm /user/your_username/output/data.txt`

ðŸ“Œ **What does this do?**

-   Deletes `data.txt` from HDFS.

bash

CopyEdit

`hdfs dfs -rm -r /user/your_username/output`

ðŸ“Œ **What does this do?**

-   Deletes **the entire directory `/output/`** and its contents.
* * *

# **ðŸ”¥ Step 5: File Permissions & ACLs in HDFS**

ðŸ“Œ **Every file in HDFS has permissions like Linux (`rwx`).**

### **âœ… 1. Check File Permissions**

bash

CopyEdit

`hdfs dfs -ls -h /user/your_username/input/`

ðŸ“Œ **What does this do?**

-   Lists files with **ownership, size, and permissions** in human-readable format (`-h`).
* * *

### **âœ… 2. Change File Permissions**

bash

CopyEdit

`hdfs dfs -chmod 755 /user/your_username/input/`

ðŸ“Œ **What does this do?**

-   Gives **read, write, and execute (rwx) permissions** to the owner.
-   Gives **read & execute (r-x) permissions** to others.
* * *

### **âœ… 3. Change File Ownership**

bash

CopyEdit

`hdfs dfs -chown your_user:your_group /user/your_username/input/`

ðŸ“Œ **What does this do?**

-   Changes **file owner and group ownership** in HDFS.
* * *

### **âœ… 4. Set ACLs for Fine-Grained Access**

bash

CopyEdit

`hdfs dfs -setfacl -m user:anotheruser:rwx /user/your_username/input/`

ðŸ“Œ **What does this do?**

-   Grants **full access (rwx)** to `anotheruser`.

bash

CopyEdit

`hdfs dfs -setfacl -b /user/your_username/input/`

ðŸ“Œ **What does this do?**

-   Removes all ACL rules from `/input/`.
* * *


