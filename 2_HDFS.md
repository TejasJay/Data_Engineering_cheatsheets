# **ğŸ”¥ Step 1: Introduction to Hadoop & HDFS**

### **ğŸ“Œ What is HDFS?**

HDFS (**Hadoop Distributed File System**) is a **fault-tolerant, distributed file system** designed to store **large-scale data** across multiple machines.

âœ… **Why use HDFS?**

-   Handles **huge datasets** (terabytes to petabytes).
-   **Scalable** â€“ Adds more nodes as storage grows.
-   **Fault-tolerant** â€“ Replicates data across machines.
* * *

## **ğŸ”¥ Step 2: HDFS Components**

HDFS has a **Master-Slave Architecture**:

| **Component** | **Function** |
| --- | --- |
| **NameNode (Master)** | Manages metadata (file locations, permissions, replication info). |
| **DataNodes (Slaves)** | Store actual data blocks. |
| **Secondary NameNode** | Helps in metadata checkpointing (not a failover node). |

* * *

## **ğŸ”¥ Step 3: Install & Start HDFS**

### **âœ… 1. Format the NameNode (Prepares HDFS for First-Time Use)**

bash

CopyEdit

`hdfs namenode -format`

ğŸ“Œ **What does this do?**

-   Initializes the **metadata storage** of the NameNode.
-   Deletes old metadata and creates a **fresh file system**.
* * *

### **âœ… 2. Start HDFS Services**

bash

CopyEdit

`start-dfs.sh`

ğŸ“Œ **What does this do?**

-   Starts **NameNode (Master)** and **DataNodes (Workers)** in the cluster.
-   Allows files to be stored and retrieved in HDFS.

ğŸ”¹ **Verify services are running:**

bash

CopyEdit

`jps`

ğŸ“Œ **What does this show?**

-   Lists running Hadoop processes (`NameNode`, `DataNode`, `SecondaryNameNode`).
* * *

### **âœ… 3. Check HDFS Cluster Status**

bash

CopyEdit

`hdfs dfsadmin -report`

ğŸ“Œ **What does this do?**

-   Displays **live DataNodes, total storage, free space, and replication factor**.
* * *

# **ğŸ”¥ Step 4: Basic HDFS Commands (Hands-On)**

ğŸ“Œ **Now letâ€™s create directories, upload files, move, and delete files in HDFS.**

* * *

### **âœ… 1. Create Directories in HDFS**

bash

CopyEdit

`hdfs dfs -mkdir /user/your_username`

ğŸ“Œ **What does this do?**

-   Creates a new directory `/user/your_username` inside HDFS.
-   Similar to `mkdir` in Linux, but for HDFS.

bash

CopyEdit

`hdfs dfs -mkdir /user/your_username/input hdfs dfs -mkdir /user/your_username/output`

ğŸ“Œ **Why create multiple directories?**

-   `/input` â†’ Stores raw files.
-   `/output` â†’ Stores processed data.

ğŸ”¹ **Verify directories were created:**

bash

CopyEdit

`hdfs dfs -ls /user/your_username`

ğŸ“Œ **What does this do?**

-   Lists all files and directories inside `/user/your_username`.
* * *

### **âœ… 2. Upload Files to HDFS**

bash

CopyEdit

`echo "Hadoop is a distributed file system" > localfile.txt hdfs dfs -put localfile.txt /user/your_username/input/`

ğŸ“Œ **What does this do?**

-   Creates a sample file `localfile.txt` in local storage.
-   `put` uploads the file to HDFS under `/user/your_username/input/`.

ğŸ”¹ **Verify file was uploaded:**

bash

CopyEdit

`hdfs dfs -ls /user/your_username/input/`

ğŸ“Œ **What does this do?**

-   Lists all files in `/user/your_username/input/` inside HDFS.
* * *

### **âœ… 3. Read Files from HDFS**

bash

CopyEdit

`hdfs dfs -cat /user/your_username/input/localfile.txt`

ğŸ“Œ **What does this do?**

-   Reads and displays the content of `localfile.txt` stored inside HDFS.
-   Similar to `cat` in Linux.
* * *

### **âœ… 4. Download Files from HDFS**

bash

CopyEdit

`hdfs dfs -get /user/your_username/input/localfile.txt .`

ğŸ“Œ **What does this do?**

-   Retrieves `localfile.txt` from HDFS and saves it in the **current directory (`.`)**.

bash

CopyEdit

`hdfs dfs -copyToLocal /user/your_username/input/localfile.txt .`

ğŸ“Œ **Whatâ€™s the difference?**

-   Both `get` and `copyToLocal` copy files from HDFS to the local file system.
-   `get` provides **progress status**, while `copyToLocal` doesnâ€™t.
* * *

### **âœ… 5. Rename & Move Files in HDFS**

bash

CopyEdit

`hdfs dfs -mv /user/your_username/input/localfile.txt /user/your_username/input/data.txt`

ğŸ“Œ **What does this do?**

-   Renames `localfile.txt` to `data.txt`.

bash

CopyEdit

`hdfs dfs -mv /user/your_username/input/data.txt /user/your_username/output/`

ğŸ“Œ **What does this do?**

-   Moves `data.txt` from `/input/` to `/output/`.

ğŸ”¹ **Check if the file was moved:**

bash

CopyEdit

`hdfs dfs -ls /user/your_username/output/`

ğŸ“Œ **What does this do?**

-   Lists the contents of `/output/` to verify the move.
* * *

### **âœ… 6. Delete Files & Directories in HDFS**

bash

CopyEdit

`hdfs dfs -rm /user/your_username/output/data.txt`

ğŸ“Œ **What does this do?**

-   Deletes `data.txt` from HDFS.

bash

CopyEdit

`hdfs dfs -rm -r /user/your_username/output`

ğŸ“Œ **What does this do?**

-   Deletes **the entire directory `/output/`** and its contents.
* * *

# **ğŸ”¥ Step 5: File Permissions & ACLs in HDFS**

ğŸ“Œ **Every file in HDFS has permissions like Linux (`rwx`).**

### **âœ… 1. Check File Permissions**

bash

CopyEdit

`hdfs dfs -ls -h /user/your_username/input/`

ğŸ“Œ **What does this do?**

-   Lists files with **ownership, size, and permissions** in human-readable format (`-h`).
* * *

### **âœ… 2. Change File Permissions**

bash

CopyEdit

`hdfs dfs -chmod 755 /user/your_username/input/`

ğŸ“Œ **What does this do?**

-   Gives **read, write, and execute (rwx) permissions** to the owner.
-   Gives **read & execute (r-x) permissions** to others.
* * *

### **âœ… 3. Change File Ownership**

bash

CopyEdit

`hdfs dfs -chown your_user:your_group /user/your_username/input/`

ğŸ“Œ **What does this do?**

-   Changes **file owner and group ownership** in HDFS.
* * *

### **âœ… 4. Set ACLs for Fine-Grained Access**

bash

CopyEdit

`hdfs dfs -setfacl -m user:anotheruser:rwx /user/your_username/input/`

ğŸ“Œ **What does this do?**

-   Grants **full access (rwx)** to `anotheruser`.

bash

CopyEdit

`hdfs dfs -setfacl -b /user/your_username/input/`

ğŸ“Œ **What does this do?**

-   Removes all ACL rules from `/input/`.
* * *


# **ğŸ”¥ 1. How HDFS Stores Data (Block-Based Storage)**

### **ğŸ“Œ Why Blocks?**

HDFS **splits large files** into **fixed-size blocks** to store across multiple machines.

ğŸ“Œ **Default Block Size:**

-   **128MB** (Hadoop 2.x & 3.x, configurable)
-   **64MB** (Hadoop 1.x)

ğŸ“Œ **How File Storage Works in HDFS:** 1ï¸âƒ£ When a file is uploaded, HDFS **divides it into blocks** (e.g., a **600MB file** â†’ 5 blocks of 128MB each).
2ï¸âƒ£ Each block is stored on **different DataNodes** to ensure redundancy & fault tolerance.
3ï¸âƒ£ The **NameNode tracks where each block is stored** in metadata.

ğŸ’¡ **Example: A 500MB file in HDFS (128MB block size)**

| Block | DataNode 1 | DataNode 2 | DataNode 3 |
| --- | --- | --- | --- |
| Block 1 (128MB) | âœ… | âœ… (Replica) | âœ… (Replica) |
| Block 2 (128MB) | âœ… | âœ… (Replica) | âœ… (Replica) |
| Block 3 (128MB) | âœ… | âœ… (Replica) | âœ… (Replica) |
| Block 4 (116MB) | âœ… | âœ… (Replica) | âœ… (Replica) |

ğŸ“Œ **View Block Size Configuration in HDFS**

bash

CopyEdit

`hdfs getconf -confKey dfs.blocksize`

ğŸ”¹ **Displays the current block size setting in bytes (default: 134217728 for 128MB).**

ğŸ“Œ **View Block Details of a File**

bash

CopyEdit

`hdfs fsck /user/your_username/input/localfile.txt -files -blocks -locations`

ğŸ”¹ **Shows how HDFS splits a file into blocks and where each block is stored.**

* * *

# **ğŸ”¥ 2. HDFS NameNode & Metadata Management**

### **ğŸ“Œ What is Metadata?**

The **NameNode doesnâ€™t store actual data**â€”it only keeps a **mapping (metadata) of files to blocks**.

ğŸ“Œ **Metadata is stored in two files:**

| **Metadata File** | **Purpose** |
| --- | --- |
| **fsimage** | A snapshot of the HDFS namespace (file structure, permissions, locations). |
| **edits log** | Tracks recent metadata changes (file creation, deletion, renaming). |

ğŸ’¡ **Example: If you create a file in HDFSâ€¦**

-   NameNode **updates `edits log` immediately**.
-   Every few minutes, the **Secondary NameNode merges `fsimage` and `edits log`** into a new `fsimage` file.

ğŸ“Œ **View fsimage & edits log (Hands-On)**

bash

CopyEdit

`ls -lh /usr/local/hadoop/tmp/dfs/name/current/`

ğŸ”¹ **Shows metadata files (`fsimage`, `edits`, `VERSION`).**

ğŸ“Œ **Check Safe Mode Status (Read-Only Mode for Metadata)**

bash

CopyEdit

`hdfs dfsadmin -safemode get`

ğŸ”¹ **If enabled, HDFS doesnâ€™t allow writes until block reports are received.**

ğŸ“Œ **Manually Force a Checkpoint (Merge fsimage & edits log)**

bash

CopyEdit

`hdfs secondarynamenode -checkpoint force`

ğŸ”¹ **Forces the Secondary NameNode to merge metadata.**

* * *

# **ğŸ”¥ 3. HDFS Replication & Fault Tolerance**

### **ğŸ“Œ How HDFS Handles Failures (Replication Mechanism)**

âœ… By default, **each block is replicated 3 times** for fault tolerance.
âœ… If a **DataNode fails**, HDFS **automatically re-replicates lost blocks**.

ğŸ“Œ **Check the Replication Factor of a File**

bash

CopyEdit

`hdfs fsck /user/your_username/input/localfile.txt -files -blocks`

ğŸ”¹ **Displays the replication factor of each block.**

ğŸ“Œ **Manually Set Replication Factor**

bash

CopyEdit

`hdfs dfs -setrep -w 2 /user/your_username/input/localfile.txt`

ğŸ”¹ **Changes replication factor to 2 (default is 3).**

ğŸ“Œ **View Missing Blocks in HDFS**

bash

CopyEdit

`hdfs fsck / -missing`

ğŸ”¹ **Lists any missing blocks that need replication.**

* * *

# **ğŸ”¥ 4. Rack Awareness in HDFS**

### **ğŸ“Œ What is Rack Awareness?**

HDFS **distributes data across multiple racks** in a data center to **protect against entire rack failures**.

âœ… Blocks are stored in **different racks** to **ensure high availability**. âœ… Default policy: **One block replica in a different rack** to avoid total data loss.

ğŸ’¡ **Example: If a Data Center has 3 Racks (`Rack-1`, `Rack-2`, `Rack-3`)**

| Block | DataNode in Rack-1 | DataNode in Rack-2 | DataNode in Rack-3 |
| --- | --- | --- | --- |
| Block 1 | âœ… (Replica 1) | âœ… (Replica 2) | âœ… (Replica 3) |

ğŸ“Œ **Check Rack Awareness Configuration**

bash

CopyEdit

`hdfs getconf -confKey net.topology.script.file.name`

ğŸ”¹ **Shows the script used for rack topology.**

ğŸ“Œ **View Blocks Placement Across Racks**

bash

CopyEdit

`hdfs fsck / -files -blocks -racks`

ğŸ”¹ **Shows which racks store each file's blocks.**

* * *

# **ğŸ”¥ 5. Simulating HDFS Failures (Hands-On)**

### **âœ… 1. Kill a DataNode to Simulate Failure**

bash

CopyEdit

`jps  # Find the DataNode process ID kill -9 <DataNode_PID>`

ğŸ”¹ **Kills a DataNode to test HDFS self-healing.**

ğŸ“Œ **Check Missing Blocks After DataNode Failure**

bash

CopyEdit

`hdfs fsck / -files -blocks -locations`

ğŸ”¹ **Lists blocks that lost replication.**

ğŸ“Œ **Force HDFS to Rebalance & Restore Replication**

bash

CopyEdit

`hdfs balancer`

ğŸ”¹ **Redistributes blocks to ensure proper replication.**

---

## ğŸ”¹ **HDFS Internal Architecture Overview**
HDFS (Hadoop Distributed File System) is a **master-slave architecture** consisting of:  
ğŸ”¹ **NameNode** (Master) â†’ Manages metadata and file system namespace  
ğŸ”¹ **DataNodes** (Slaves) â†’ Store actual file blocks and send heartbeats to NameNode  
ğŸ”¹ **Secondary NameNode** â†’ Assists in checkpointing metadata (not a failover NameNode!)  

---

# 1ï¸âƒ£ **NameNode & Metadata Management** ğŸ–¥ï¸  

### **ğŸ”¹ What is `fsimage` & `edit logs`?**
ğŸ“‚ **NameNode stores metadata**, such as file locations, permissions, and directory structure. This is stored in two files:  
1ï¸âƒ£ **fsimage** â†’ A complete snapshot of the file system metadata  
2ï¸âƒ£ **edit logs** â†’ Records recent changes (file creation, deletion, etc.)  

ğŸ‘‰ When the NameNode starts, it **loads fsimage** and **replays edit logs** to reconstruct the latest state of the file system.  

### âœ… **Hands-on Command: Checking Safe Mode**
**Safe Mode** is when the NameNode temporarily **prevents write operations** while waiting for DataNodes to report back.  

ğŸ› ï¸ Check if Safe Mode is ON or OFF:  
```bash
hdfs dfsadmin -safemode get
```
âœ… If ON, disable it manually:  
```bash
hdfs dfsadmin -safemode leave
```

### **ğŸ”¹ How does NameNode handle failure?**
When the **NameNode crashes**, all metadata in RAM is lost. To prevent this:  
âœ… **Checkpointing** â†’ Periodically merges `fsimage` & `edit logs` to reduce recovery time.  
âœ… **Secondary NameNode (SNN)** â†’ Takes snapshots to help with recovery (but is NOT a failover NameNode).  

ğŸ› ï¸ **Check Last Checkpoint Time**  
```bash
hdfs dfsadmin -fetchImage .
ls -lh fsimage_*
```

---

# 2ï¸âƒ£ **DataNodes & Storage** ğŸ—„ï¸  

### **ğŸ”¹ How DataNodes Store Blocks**
ğŸ”¹ Files are **split into blocks** (default size **128MB or 256MB**)  
ğŸ”¹ Blocks are stored **across multiple DataNodes**  
ğŸ”¹ Each block is **replicated** to ensure fault tolerance  

âœ… **Check where blocks are stored for a file:**  
```bash
hdfs fsck / -files -blocks -locations
```
ğŸ‘‰ This will list **block locations on DataNodes**.  

### **ğŸ”¹ How Replication Works**
HDFS **replicates blocks (default: 3 copies)** to prevent data loss.  
âœ… Check the replication factor:  
```bash
hdfs getconf -confKey dfs.replication
```
âœ… Change the replication factor for a file:  
```bash
hdfs dfs -setrep -w 2 /path/to/file
```

### **ğŸ”¹ How HDFS Balances Data**
If some DataNodes have **too much data**, HDFS **balances** data across the cluster.  
âœ… Run the balancer manually:  
```bash
hdfs balancer
```

---

# 3ï¸âƒ£ **HDFS Read & Write Process** ğŸ“¥ğŸ“¤  

### **ğŸ”¹ How Files are Written to HDFS**
ğŸ“Œ When a client writes a file:  
1ï¸âƒ£ **Splits into blocks** (default: **128MB**)  
2ï¸âƒ£ **Contact NameNode** â†’ Assigns DataNodes to store each block  
3ï¸âƒ£ **DataNodes replicate the block** to ensure fault tolerance  

âœ… **Check where a file is stored after writing:**  
```bash
hdfs fsck /user/$(whoami)/filename.txt -files -blocks -locations
```

### **ğŸ”¹ How Files are Read from HDFS**
ğŸ“Œ When a client reads a file:  
1ï¸âƒ£ **Contacts NameNode** â†’ Gets block locations  
2ï¸âƒ£ **Reads data directly from DataNodes** (closest copy first)  
3ï¸âƒ£ **Reconstructs the file on the client side**  

âœ… **Read file content from HDFS:**  
```bash
hdfs dfs -cat /user/$(whoami)/filename.txt
```

---

# 4ï¸âƒ£ **Rack Awareness in HDFS** ğŸŒ  

### **ğŸ”¹ Why is Rack Awareness Important?**
ğŸ› ï¸ HDFS ensures data **is not lost even if an entire rack fails** by distributing replicas across different racks.  
1ï¸âƒ£ NameNode **assigns blocks to different racks** to ensure redundancy.  
2ï¸âƒ£ Default policy â†’ **2 copies on the same rack, 1 copy on a different rack**.  

âœ… **Check rack awareness settings:**  
```bash
hdfs getconf -confKey net.topology.script.file.name
```

### **ğŸ”¹ How to Configure Rack Awareness**
ğŸ› ï¸ Edit the Hadoop rack script:  
```bash
nano $HADOOP_HOME/etc/hadoop/topology.script
```
Add:  
```bash
#!/bin/bash
# Assign rack based on hostname
if [[ $1 == "datanode1" ]]; then
  echo "/rack1"
elif [[ $1 == "datanode2" ]]; then
  echo "/rack2"
else
  echo "/default-rack"
fi
```
âœ… **Make it executable:**  
```bash
chmod +x $HADOOP_HOME/etc/hadoop/topology.script
```

---

# ğŸ”¹ **Key Configuration Files in HDFS**

HDFS configuration is managed using **four key XML files**, each serving a different role in Hadoopâ€™s architecture. These files define how different components interact, how data is stored, and how jobs are executed.

## **ğŸ“Œ 1ï¸âƒ£ core-site.xml**

âœ… **Defines fundamental Hadoop properties**
âœ… Configures **default filesystem (fs.defaultFS)**
âœ… Controls Hadoop **I/O, authentication, and compression**

ğŸ“Œ **Location:**

bash

CopyEdit

`$HADOOP_HOME/etc/hadoop/core-site.xml`

ğŸ“Œ **Example Configuration:**

xml

CopyEdit

`<configuration>   <!-- Default Filesystem URI -->   <property>     <name>fs.defaultFS</name>     <value>hdfs://localhost:9000</value>   </property>    <!-- Hadoop Temporary Directory -->   <property>     <name>hadoop.tmp.dir</name>     <value>/usr/local/hadoop/tmp</value>   </property>    <!-- I/O File Buffer Size -->   <property>     <name>io.file.buffer.size</name>     <value>131072</value> <!-- 128KB -->   </property> </configuration>`

ğŸ“Œ **Practical Verification:**

bash

CopyEdit

`hdfs getconf -confKey fs.defaultFS`

ğŸ“Œ **To check I/O performance:**

bash

CopyEdit

`hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar TestDFSIO -write -nrFiles 5 -size 10MB`

* * *

## **ğŸ“Œ 2ï¸âƒ£ hdfs-site.xml**

âœ… **Configures NameNode, DataNode, and block replication settings**
âœ… Controls **replication, permissions, and block size**
âœ… Defines **safe mode & quotas**

ğŸ“Œ **Location:**

bash

CopyEdit

`$HADOOP_HOME/etc/hadoop/hdfs-site.xml`

ğŸ“Œ **Example Configuration:**

xml

CopyEdit

`<configuration>   <!-- NameNode directory -->   <property>     <name>dfs.namenode.name.dir</name>     <value>file:///usr/local/hadoop/hdfs/namenode</value>   </property>    <!-- DataNode storage directory -->   <property>     <name>dfs.datanode.data.dir</name>     <value>file:///usr/local/hadoop/hdfs/datanode</value>   </property>    <!-- Default replication factor -->   <property>     <name>dfs.replication</name>     <value>3</value>   </property>    <!-- Default block size -->   <property>     <name>dfs.blocksize</name>     <value>134217728</value> <!-- 128MB -->   </property>    <!-- Safe Mode Threshold -->   <property>     <name>dfs.namenode.safemode.threshold-pct</name>     <value>0.999</value>   </property> </configuration>`

ğŸ“Œ **Practical Verification:**

bash

CopyEdit

`hdfs dfsadmin -report`

bash

CopyEdit

`hdfs fsck /`

ğŸ“Œ **To test replication factor:**

bash

CopyEdit

`hdfs dfs -setrep 2 /user/hadoop/sample.txt`

* * *

## **ğŸ“Œ 3ï¸âƒ£ mapred-site.xml**

âœ… **Configures MapReduce execution & scheduling**
âœ… Defines **job tracker location, memory settings**
âœ… Manages **task parallelism**

ğŸ“Œ **Location:**

bash

CopyEdit

`$HADOOP_HOME/etc/hadoop/mapred-site.xml`

ğŸ“Œ **Example Configuration:**

xml

CopyEdit

`<configuration>   <!-- Define MapReduce framework -->   <property>     <name>mapreduce.framework.name</name>     <value>yarn</value>   </property>    <!-- Reduce tasks per node -->   <property>     <name>mapreduce.job.reduces</name>     <value>2</value>   </property>    <!-- Mapper and Reducer memory settings -->   <property>     <name>mapreduce.map.memory.mb</name>     <value>1024</value>   </property>    <property>     <name>mapreduce.reduce.memory.mb</name>     <value>2048</value>   </property> </configuration>`

ğŸ“Œ **Practical Verification:**

bash

CopyEdit

`hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar wordcount /input /output`

ğŸ“Œ **To check running jobs:**

bash

CopyEdit

`mapred job -list`

* * *

## **ğŸ“Œ 4ï¸âƒ£ yarn-site.xml**

âœ… **Configures YARN (Yet Another Resource Negotiator)**
âœ… Controls **ResourceManager, NodeManager, and scheduling policies**
âœ… Defines **memory, CPU limits, and application scheduling**

ğŸ“Œ **Location:**

bash

CopyEdit

`$HADOOP_HOME/etc/hadoop/yarn-site.xml`

ğŸ“Œ **Example Configuration:**

xml

CopyEdit

`<configuration>   <!-- Resource Manager Address -->   <property>     <name>yarn.resourcemanager.address</name>     <value>localhost:8032</value>   </property>    <!-- Enable NodeManager -->   <property>     <name>yarn.nodemanager.aux-services</name>     <value>mapreduce_shuffle</value>   </property>    <!-- Memory Allocation -->   <property>     <name>yarn.scheduler.maximum-allocation-mb</name>     <value>4096</value>   </property>    <property>     <name>yarn.scheduler.minimum-allocation-mb</name>     <value>512</value>   </property> </configuration>`

ğŸ“Œ **Practical Verification:**

bash

CopyEdit

`yarn node -list`

bash

CopyEdit

`yarn application -list`

* * *

# **ğŸ“Œ Tuning HDFS Performance**

Performance tuning in HDFS involves optimizing **block size, replication factor, compression, and resource allocation**. Let's break it down step by step.

* * *

## **ğŸ›  1ï¸âƒ£ Adjusting Block Size (dfs.blocksize)**

âœ… **What is it?**
HDFS stores data in blocks, and the default block size is **128MB**. A larger block size reduces metadata overhead and improves read/write efficiency for large files.

âœ… **When to change it?**

-   **Increase block size (256MB-512MB)** for **large files** (e.g., videos, logs).
-   **Decrease block size (64MB)** for **small files** to avoid wasted space.

ğŸ“Œ **Configuration (hdfs-site.xml):**

xml

CopyEdit

`<property>   <name>dfs.blocksize</name>   <value>268435456</value> <!-- 256MB --> </property>`

ğŸ“Œ **Verify block size for a file:**

bash

CopyEdit

`hdfs fsck /path/to/file -files -blocks -locations`

ğŸ“Œ **Upload a file with a specific block size:**

bash

CopyEdit

`hdfs dfs -Ddfs.blocksize=134217728 -put largefile.txt /user/hadoop/`

* * *

## **ğŸ›  2ï¸âƒ£ Adjusting Replication Factor (dfs.replication)**

âœ… **What is it?**
HDFS replicates each block **(default: 3 copies)** to different DataNodes for fault tolerance.

âœ… **When to change it?**

-   **Reduce to 2** for **low-priority data** to save space.
-   **Increase to 4+** for **critical data** to improve fault tolerance.

ğŸ“Œ **Configuration (hdfs-site.xml):**

xml

CopyEdit

`<property>   <name>dfs.replication</name>   <value>2</value> </property>`

ğŸ“Œ **Change replication factor for an existing file:**

bash

CopyEdit

`hdfs dfs -setrep 2 /user/hadoop/myfile.txt`

ğŸ“Œ **Check replication of a file:**

bash

CopyEdit

`hdfs fsck / -files -blocks`

* * *

## **ğŸ›  3ï¸âƒ£ Enabling Compression for Storage Efficiency**

âœ… **What is it?**
HDFS supports **compression** to reduce storage space and speed up data transfers.

âœ… **Types of Compression:**

| Compression Type | Pros | Cons |
| --- | --- | --- |
| Gzip (.gz) | High compression ratio | Not splittable (bad for MapReduce) |
| Bzip2 (.bz2) | Splittable & efficient | Slower compression |
| LZO | Splittable & fast | Lower compression ratio |

ğŸ“Œ **Enable compression in core-site.xml:**

xml

CopyEdit

`<property>   <name>io.compression.codecs</name>   <value>org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec</value> </property>`

ğŸ“Œ **Compress files in HDFS:**

bash

CopyEdit

`hdfs dfs -text /user/hadoop/data.txt | gzip > data.gz hdfs dfs -put data.gz /user/hadoop/`

ğŸ“Œ **Verify compression type:**

bash

CopyEdit

`hadoop checknative -a`

* * *

## **ğŸ›  4ï¸âƒ£ Optimize Memory & I/O Buffers**

âœ… **Increase I/O buffer size** (core-site.xml) for **faster reads/writes**:

xml

CopyEdit

`<property>   <name>io.file.buffer.size</name>   <value>131072</value> <!-- 128KB --> </property>`

âœ… **Adjust Memory Settings in YARN (yarn-site.xml)**

xml

CopyEdit

`<property>   <name>yarn.scheduler.minimum-allocation-mb</name>   <value>1024</value> <!-- Min 1GB per container --> </property>  <property>   <name>yarn.scheduler.maximum-allocation-mb</name>   <value>8192</value> <!-- Max 8GB per container --> </property>`

ğŸ“Œ **Check current buffer size:**

bash

CopyEdit

`hdfs getconf -confKey io.file.buffer.size`

* * *


# **ğŸ“Œ HDFS High Availability (HA) ğŸ› ï¸**

HDFS **High Availability (HA)** ensures that the **NameNode** is always available, eliminating a **single point of failure** (SPOF). It uses **Active-Standby NameNodes** and **Quorum Journal Manager (QJM)** for failover.

* * *

## **ğŸ›  1ï¸âƒ£ Understanding Active & Standby NameNodes**

### âœ… **What is it?**

HDFS HA sets up **two NameNodes**:

-   **ğŸ”µ Active NameNode (NN1)** â€“ Handles client requests.
-   **ğŸŸ¢ Standby NameNode (NN2)** â€“ Synchronizes metadata with NN1 and takes over in case of failure.

### âœ… **How does it work?**

-   Both NameNodes **share edit logs** using **Quorum Journal Manager (QJM)**.
-   If the Active NameNode **fails**, the **Standby** automatically takes over.

ğŸ“Œ **Check the active/standby state:**

bash

CopyEdit

`hdfs haadmin -getServiceState nn1 hdfs haadmin -getServiceState nn2`

* * *

## **ğŸ›  2ï¸âƒ£ Configuring Quorum Journal Manager (QJM) ğŸ“’**

### âœ… **What is QJM?**

-   Stores **edit logs** across multiple **JournalNodes (JNs)**.
-   Ensures that changes are written to a **majority (quorum)** before applying.

### âœ… **Setup Steps:**

1ï¸âƒ£ **Modify `hdfs-site.xml`**

xml

CopyEdit

`<property>   <name>dfs.nameservices</name>   <value>mycluster</value> </property>  <property>   <name>dfs.ha.namenodes.mycluster</name>   <value>nn1,nn2</value> </property>  <property>   <name>dfs.namenode.rpc-address.mycluster.nn1</name>   <value>192.168.2.100:8020</value> </property>  <property>   <name>dfs.namenode.rpc-address.mycluster.nn2</name>   <value>192.168.2.101:8020</value> </property>  <property>   <name>dfs.namenode.shared.edits.dir</name>   <value>qjournal://192.168.2.102:8485;192.168.2.103:8485;192.168.2.104:8485/mycluster</value> </property>`

ğŸ’¡ **Explanation:**

-   `dfs.nameservices` â†’ Logical cluster name (`mycluster`).
-   `dfs.ha.namenodes.mycluster` â†’ Lists **both NameNodes**.
-   `dfs.namenode.shared.edits.dir` â†’ Points to **three JournalNodes (QJM)**.
* * *

2ï¸âƒ£ **Modify `core-site.xml`**

xml

CopyEdit

`<property>   <name>fs.defaultFS</name>   <value>hdfs://mycluster</value> </property>`

3ï¸âƒ£ **Start JournalNodes on all nodes**

bash

CopyEdit

`hdfs journalnode`

4ï¸âƒ£ **Initialize shared edits directory**

bash

CopyEdit

`hdfs namenode -initializeSharedEdits`

* * *

## **ğŸ›  3ï¸âƒ£ Configuring Failover Controller (ZKFC) ğŸ”„**

### âœ… **What is ZKFC?**

-   **ZooKeeper Failover Controller (ZKFC)** monitors NameNodes.
-   If the Active NameNode **fails**, it **automatically promotes** the Standby.

### âœ… **Steps to Configure ZKFC:**

1ï¸âƒ£ **Modify `hdfs-site.xml`**

xml

CopyEdit

`<property>   <name>dfs.ha.automatic-failover.enabled</name>   <value>true</value> </property>`

2ï¸âƒ£ **Start Zookeeper & ZKFC on all nodes**

bash

CopyEdit

`zkServer.sh start hdfs zkfc -formatZK`

3ï¸âƒ£ **Manually trigger failover (for testing)**

bash

CopyEdit

`hdfs haadmin -failover nn1 nn2`

* * *

## **ğŸ›  4ï¸âƒ£ Testing High Availability ğŸ”**

1ï¸âƒ£ **Check which NameNode is active:**

bash

CopyEdit

`hdfs haadmin -getServiceState nn1 hdfs haadmin -getServiceState nn2`

2ï¸âƒ£ **Simulate a NameNode failure:**

bash

CopyEdit

`kill -9 <NN1_PID>`

3ï¸âƒ£ **Verify Standby becomes Active:**

bash

CopyEdit

`hdfs haadmin -getServiceState nn2`

